# Pipeboard: Sincroniza√ß√£o com a base de dados do Pipedrive üöÄ

[![Vers√£o do Python](https://img.shields.io/badge/python-3.12-blue)](https://www.python.org/) [![Vers√£o do Prefect](https://img.shields.io/badge/prefect-3.x-green)](https://prefect.io/) [![Licen√ßa](https://img.shields.io/badge/license-MIT-lightgrey)](LICENSE)

Objetivos:
* **Criar relat√≥rios e dashboards totalmente personalizados;**
* **An√°lises profundas e cruzamento de dados;**
* **Tomada de decis√£o baseada em dados;**
* **Hist√≥rico completo e confi√°vel.**

---

## üîñ Sum√°rio

* [O que √© o Pipeboard?](#o-que-√©-o-pipeboard)
* [Principais Funcionalidades](#principais-funcionalidades)
* [Arquitetura do Projeto](#arquitetura-do-projeto)
* [Tecnologias Utilizadas](#tecnologias-utilizadas)
* [Pr√©-requisitos](#pr√©-requisitos)
* [Configura√ß√£o e Instala√ß√£o](#configura√ß√£o-e-instala√ß√£o)
* [Executando o Projeto](#executando-o-projeto)
* [Fluxo de Sincroniza√ß√£o](#fluxo-de-sincroniza√ß√£o)
* [Funcionamento T√©cnico Detalhado](#funcionamento-t√©cnico-detalhado)
* [Monitoramento](#monitoramento)
* [Estrutura de Diret√≥rios](#estrutura-de-diret√≥rios)
* [Vari√°veis de Ambiente Essenciais](#vari√°veis-de-ambiente-essenciais)
* [Desenvolvimento e Contribui√ß√£o](#desenvolvimento-e-contribui√ß√£o)
* [Solu√ß√£o de Problemas (FAQ)](#solu√ß√£o-de-problemas-faq)
* [Licen√ßa](#licen√ßa)

## O que √© o Pipeboard?

Pipeboard √© uma solu√ß√£o robusta de ETL (Extract, Transform, Load) e sincroniza√ß√£o de dados, projetada especificamente para integrar o Pipedrive a um banco de dados PostgreSQL, que pode ser usado como fonte do Metabase. Seu foco √© lidar com grandes volumes de dados, oferecendo sincroniza√ß√£o incremental eficiente, capacidade de backfill completo, e um sistema de orquestra√ß√£o resiliente e monitor√°vel.

O projeto visa fornecer uma base s√≥lida para Business Intelligence (BI).

## Principais Funcionalidades

O Pipeboard √© constru√≠do com um conjunto de funcionalidades poderosas para garantir uma integra√ß√£o de dados eficiente e confi√°vel:

* **Sincroniza√ß√£o Incremental e Backfill Completo:** Mant√©m seu banco de dados atualizado com as √∫ltimas altera√ß√µes do Pipedrive e permite a carga inicial de todo o hist√≥rico de dados.
* **Extra√ß√£o de Dados Eficiente:** Utiliza streaming paginado para consumir as APIs V1 e V2 do Pipedrive, garantindo baixo consumo de mem√≥ria mesmo com grandes volumes de dados.
* **Transforma√ß√£o de Dados Robusta:** Valida√ß√£o de dados com Pydantic, achatamento (flattening) de campos customizados complexos e normaliza√ß√£o de informa√ß√µes como endere√ßos e contatos.
* **Gerenciamento Din√¢mico de Esquema no Banco de Dados:** Cria e atualiza tabelas e colunas no PostgreSQL automaticamente conforme novos campos s√£o detectados no Pipedrive, sem necessidade de migra√ß√µes manuais.
* **Orquestra√ß√£o Avan√ßada com Prefect:** Fluxos de trabalho modulares e reutiliz√°veis, com gerenciamento de depend√™ncias entre sincroniza√ß√µes de diferentes entidades (ex: usu√°rios s√£o sincronizados antes de neg√≥cios), agendamentos flex√≠veis (via cron) e gatilhos baseados em eventos.
* **Monitoramento Abrangente:** Integra√ß√£o nativa com Prometheus para coleta de m√©tricas detalhadas e um dashboard Grafana pr√©-configurado para visualiza√ß√£o da sa√∫de da API, performance dos fluxos ETL, uso de cache, estado do banco de dados e muito mais.
* **Resili√™ncia e Confiabilidade:** Implementa padr√µes como Circuit Breaker e retries exponenciais para chamadas √† API Pipedrive, protegendo o sistema contra falhas de rede e limita√ß√µes tempor√°rias da API.
* **Cache Inteligente:** Utiliza Redis para armazenar em cache respostas da API Pipedrive (especialmente para metadados e entidades menos vol√°teis), reduzindo o n√∫mero de chamadas e o consumo de tokens da API.
* **Containeriza√ß√£o com Docker:** Todos os componentes s√£o containerizados, facilitando a implanta√ß√£o, o dimensionamento e a portabilidade entre diferentes ambientes.

## Arquitetura do Projeto

O Pipeboard adota uma arquitetura hexagonal (tamb√©m conhecida como Ports and Adapters), separando claramente as responsabilidades:

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  orchestration/ (Fluxos Prefect)‚îÇ<-- Camada de Orquestra√ß√£o e Regras de Neg√≥cio da Sincroniza√ß√£o
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ core/       ‚îÇ infrastructure/  ‚îÇ<-- Camada de L√≥gica de Neg√≥cio Pura e Camada de Infraestrutura
‚îÇ  ‚îú schemas  ‚îÇ  ‚îú clients HTTP  ‚îÇ   (Adaptadores para tecnologias externas)
‚îÇ  ‚îú services ‚îÇ  ‚îú db repositories‚îÇ
‚îÇ  ‚îî utils    ‚îÇ  ‚îú redis cache   ‚îÇ
‚îÇ             ‚îÇ  ‚îú observability ‚îÇ
‚îÇ             ‚îÇ  ‚îî config        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
````

  * **`core/`**: Cont√©m a l√≥gica de neg√≥cio principal, como os esquemas Pydantic (defini√ß√£o das entidades do Pipedrive) e utilit√°rios de transforma√ß√£o de dados. √â independente de frameworks.
  * **`infrastructure/`**: Implementa os adaptadores para tecnologias externas: cliente HTTP para a API Pipedrive, reposit√≥rios para intera√ß√£o com o PostgreSQL, cache Redis, configura√ß√£o de logging e observabilidade (m√©tricas).
  * **`orchestration/`**: Define os fluxos de ETL utilizando Prefect, incluindo a l√≥gica de sincroniza√ß√£o para cada entidade, agendamentos e depend√™ncias entre fluxos.

## Tecnologias Utilizadas

  * **Linguagem Principal**: Python 3.12
  * **Orquestra√ß√£o de Workflow**: Prefect 3.x
  * **Banco de Dados (Destino)**: PostgreSQL 14+
  * **Cache**: Redis 7+
  * **Monitoramento e M√©tricas**: Prometheus, Grafana, Pushgateway
  * **Cliente HTTP e Resili√™ncia**: `requests`, `tenacity` (para retries), `pybreaker` (para circuit breaker)
  * **Valida√ß√£o de Dados**: Pydantic
  * **Logging Estruturado**: `structlog`
  * **Containeriza√ß√£o**: Docker & Docker Compose
  * **CI/CD**: GitHub Actions (para build e push de imagens Docker)

## Pr√©-requisitos

  * Docker Engine
  * Docker Compose
  * Python 3.12 (para desenvolvimento local e execu√ß√£o de scripts auxiliares, se necess√°rio fora dos containers)
  * Acesso a uma inst√¢ncia Pipedrive com uma chave de API v√°lida.
  * (Opcional) Conta no Docker Hub se voc√™ planeja modificar e hospedar suas pr√≥prias imagens.

## Configura√ß√£o e Instala√ß√£o

1.  **Clone o Reposit√≥rio:**

    ```bash
    git clone [https://github.com/seu-usuario/pipeboard.git](https://github.com/seu-usuario/pipeboard.git)
    cd pipeboard
    ```

2.  **Crie e Configure o Arquivo `.env`:**
    Copie o arquivo `.env.example` (se existir) para `.env` na raiz do projeto ou crie um novo. Preencha com suas credenciais e configura√ß√µes. Veja a se√ß√£o [Vari√°veis de Ambiente Essenciais](https://www.google.com/search?q=%23vari%C3%A1veis-de-ambiente-essenciais) para mais detalhes.
    Exemplo de `.env`:

    ```dotenv
    # Pipedrive
    PIPEDRIVE_API_KEY=SEU_API_KEY_DO_PIPEDRIVE

    # PostgreSQL (usado pelo docker-compose e pela aplica√ß√£o)
    POSTGRES_DB=pipeboard_db
    POSTGRES_USER=pipeboard_user
    POSTGRES_PASSWORD=sua_senha_segura
    POSTGRES_HOST=db # Nome do servi√ßo no docker-compose
    POSTGRES_PORT=5432
    DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

    # Redis (usado pelo docker-compose e pela aplica√ß√£o)
    REDIS_URL=redis://redis:6379/0 # 'redis' √© o nome do servi√ßo no docker-compose

    # Prefect
    PREFECT_API_URL=http://orion:4200/api # 'orion' √© o nome do servi√ßo no docker-compose
    PREFECT_SERVER_API_HOST=0.0.0.0
    PREFECT_SERVER_API_PORT=4200 # Porta interna do container Orion
    HOST_PREFECT_PORT=4200 # Porta exposta no host para acessar a UI do Prefect

    # Configura√ß√µes do Worker e Deployments Prefect
    PREFECT_WORK_POOL_NAME=pipeboard-docker-pool
    IMAGE_NAME=mrschrodingers/pipeboard-flow # Imagem base para os fluxos
    DEFAULT_DOCKER_NETWORK_NAME=prefect_internal_network # Nome da rede Docker criada pelo compose

    # Monitoramento
    PUSHGATEWAY_ADDRESS=pushgateway:9091 # 'pushgateway' √© o nome do servi√ßo
    HOST_METRICS_PORT=8082 # Porta exposta para m√©tricas do worker
    HOST_GRAFANA_PORT=3000 # Porta exposta para Grafana

    # Docker Registry (opcional, se for fazer push para um registry privado)
    DOCKER_USER=
    DOCKER_PASS=
    DOCKER_REGISTRY_URL=
    ```

3.  **Construa as Imagens Docker e Inicie os Servi√ßos:**
    O script `run_project.sh` automatiza a constru√ß√£o das imagens Docker, o push (se configurado para um registry) e o rein√≠cio dos servi√ßos via Docker Compose. Este √© o m√©todo recomendado para iniciar o ambiente.

    ```bash
    chmod +x run_project.sh
    ./run_project.sh
    ```

    Alternativamente, para apenas subir os servi√ßos usando as imagens definidas no `docker-compose.yml` (que podem ser do Docker Hub ou constru√≠das localmente se voc√™ remover as diretivas `image:` e deixar apenas `build:`):

    ```bash
    docker compose up -d --build
    ```

    O servi√ßo `prefect-setup` no `docker-compose.yml` cuidar√° automaticamente da cria√ß√£o dos blocos Prefect necess√°rios e do registro dos deployments dos fluxos na primeira vez que o ambiente √© iniciado (ou sempre que o Orion √© reiniciado sem persist√™ncia de seus dados).

4.  **Verifique os Logs:**
    Acompanhe os logs para garantir que todos os servi√ßos iniciaram corretamente:

    ```bash
    docker compose logs -f
    ```

    Procure por mensagens de sucesso do `prefect-setup` e do `worker`.

## Executando o Projeto

  * **Iniciar todos os servi√ßos:**
    ```bash
    ./run_project.sh
    ```
    ou, se as imagens j√° estiverem constru√≠das/puxadas:
    ```bash
    docker compose up -d
    ```
  * **Acessar a Interface do Prefect:**
    Abra seu navegador e acesse `http://localhost:${HOST_PREFECT_PORT:-4200}` (por padr√£o, `http://localhost:4200`).
  * **Acessar o Grafana:**
    Abra seu navegador e acesse `http://localhost:${HOST_GRAFANA_PORT:-3000}` (por padr√£o, `http://localhost:3000`). O dashboard do Pipeboard deve estar dispon√≠vel (pode requerer importa√ß√£o manual do JSON em `docs/grafana/grafana_dashboard.json` na primeira vez ou configura√ß√£o de provisionamento).
  * **Execu√ß√£o dos Fluxos de Sincroniza√ß√£o:**
      * O fluxo `Sync Pipedrive Users` √© agendado para rodar a cada 4 horas via cron.
      * Os demais fluxos s√£o encadeados e disparados automaticamente pela conclus√£o bem-sucedida do fluxo anterior, conforme o diagrama abaixo.
      * Voc√™ tamb√©m pode disparar execu√ß√µes manualmente pela UI do Prefect.

## Fluxo de Sincroniza√ß√£o

Os fluxos de sincroniza√ß√£o do Pipedrive s√£o orquestrados pelo Prefect, seguindo uma cadeia de depend√™ncias para garantir a integridade dos dados. O fluxo principal inicia-se com a sincroniza√ß√£o de usu√°rios e prossegue at√© a transforma√ß√£o final dos dados para BI.

```mermaid
graph TD
    A["Sync Pipedrive Users </br>(Default: A cada 4h)"] --> B(Sync Pipedrive Pipelines);
    B --> C(Sync Pipedrive Stages);
    C --> D(Sync Pipedrive Organizations);
    D --> E(Sync Pipedrive Persons);
    E --> F(Sync Pipedrive Deals);
    F --> G(Sync Pipedrive Activities);
    G --> H(Sync Pipedrive Activity Types);
    H --> I(Main BI Transformation);

    classDef cronNode fill:#D1E8FF,stroke:#3478BE,stroke-width:2px;
    class A cronNode;
```

**Etapas do Processo:**

1.  **Extra√ß√£o (Extract):** O `PipedriveAPIClient` busca os dados de cada entidade (Neg√≥cios, Pessoas, Organiza√ß√µes, etc.) da API do Pipedrive, utilizando pagina√ß√£o por cursor (API v2) ou start/limit (API v1) para lidar com grandes volumes de dados de forma eficiente.
2.  **Transforma√ß√£o (Transform):**
      * Os dados brutos s√£o validados e parseados utilizando esquemas Pydantic espec√≠ficos para cada entidade.
      * O `PipedriveEntitySynchronizer` "explode" campos complexos e customizados em colunas at√¥micas e normaliza os dados.
3.  **Carregamento (Load):** O `RepositorioBase` persiste os DataFrames transformados no PostgreSQL. Ele gerencia a cria√ß√£o e migra√ß√£o din√¢mica de tabelas e colunas, e utiliza estrat√©gias de `UPSERT` (INSERT ON CONFLICT DO UPDATE) otimizadas (via `execute_values` para lotes menores ou `COPY` para um staging table para lotes maiores).
4.  **Enriquecimento (Enrichment):** Ap√≥s o carregamento principal de cada entidade, alguns fluxos executam um passo de enriquecimento SQL para adicionar informa√ß√µes de tabelas relacionadas (ex: adicionar nome do propriet√°rio a um neg√≥cio).
5.  **Transforma√ß√£o BI (BI Transformation):** O fluxo `Main BI Transformation` consolida dados de v√°rias tabelas sincronizadas (neg√≥cios, pessoas, organiza√ß√µes, atividades) em uma tabela `main_bi` denormalizada, pronta para an√°lises e dashboards.

## Funcionamento T√©cnico Detalhado

  * **Extra√ß√£o de Dados Paginada:** O `PipedriveAPIClient` usa o m√©todo `stream_all_entities` para buscar dados. Para endpoints V2, ele gerencia a pagina√ß√£o por cursor (`next_cursor`). Para endpoints V1, utiliza o sistema de `start` e `limit`. Isso garante que os dados sejam processados em lotes, evitando o consumo excessivo de mem√≥ria.
  * **Transforma√ß√£o e Valida√ß√£o com `PipedriveEntitySynchronizer`:**
      * Esta classe √© o cora√ß√£o da sincroniza√ß√£o de cada entidade.
      * **Valida√ß√£o:** Utiliza `utils.validate_parallel` (que emprega um `ThreadPoolExecutor`) para validar os dados brutos da API contra os esquemas Pydantic correspondentes em paralelo.
      * **Manipuladores Espec√≠ficos:** Permite a defini√ß√£o de fun√ß√µes `specific_field_handlers` para tratar colunas com estruturas aninhadas ou formatos especiais (ex: emails, telefones, endere√ßos), transformando-as em colunas normalizadas.
      * **Campos Customizados:** Busca metadados dos campos customizados (`/dealFields`, `/personFields`, etc.) e utiliza um mapa de fun√ß√µes (`_FN_MAP`) para "explodir" os valores desses campos em colunas dedicadas no DataFrame, com nomes `slugificados`.
  * **Carregamento Inteligente com `RepositorioBase`:**
      * **Cria√ß√£o/Migra√ß√£o de Esquema:** Antes de carregar os dados, o reposit√≥rio verifica se a tabela existe. Se n√£o, cria-a com base nos tipos de dados do DataFrame e na `SchemaConfig` (PKs, √≠ndices). Se a tabela existe, compara as colunas e tipos do DataFrame com o esquema existente e aplica `ALTER TABLE` para adicionar novas colunas ou modificar tipos (com cautela para n√£o quebrar colunas PK ou de particionamento).
      * **Upsert Otimizado:** Escolhe entre duas estrat√©gias de upsert:
          * `_upsert_dynamic`: Para DataFrames menores que `staging_threshold` (default 50 linhas, mas recomend√°vel aumentar), usa `psycopg2.extras.execute_values` com `INSERT ... ON CONFLICT ... DO UPDATE`. √â eficiente para um n√∫mero moderado de linhas.
          * `_upsert_staging`: Para DataFrames maiores, cria uma tabela tempor√°ria, carrega os dados nela via `COPY` (muito mais r√°pido para grandes volumes) e, em seguida, executa `UPDATE` nos registros existentes e `INSERT` nos novos registros a partir da tabela tempor√°ria.
  * **L√≥gica de Sincroniza√ß√£o Incremental:**
      * A cada execu√ß√£o bem-sucedida de um fluxo, o timestamp √© registrado na tabela `etl_flow_meta`.
      * Nas execu√ß√µes subsequentes, o `PipedriveEntitySynchronizer` recebe o par√¢metro `updated_since` (com um pequeno `skew` de seguran√ßa), permitindo que a API do Pipedrive retorne apenas registros alterados desde essa data.
      * Alguns fluxos (ex: `sync_deals_flow`) tamb√©m verificam se suas entidades dependentes (ex: `pessoas`, `organizacoes`) foram atualizadas recentemente. Se sim, eles podem optar por um `full_refresh` para garantir a consist√™ncia, mesmo que o pr√≥prio fluxo de deals n√£o tenha sido marcado para full refresh.
  * **Orquestra√ß√£o com Prefect:**
      * **Deployments:** Cada fluxo de sincroniza√ß√£o √© definido como um Prefect Deployment nos arquivos dentro de `orchestration/plugins/`. Esses deployments especificam o nome, descri√ß√£o, tags, agendamento (para `sync_users_flow`) ou gatilhos, o work pool (`PREFECT_WORK_POOL_NAME`), a imagem Docker a ser usada (`IMAGE_NAME`), e vari√°veis de ambiente.
      * **Work Pool:** Um work pool do tipo Docker √© configurado (default `pipeboard-docker-pool`) para executar os fluxos em containers Docker.
      * **Triggers:** A maioria dos fluxos √© acionada pela conclus√£o bem-sucedida do fluxo anterior na cadeia, usando `DeploymentEventTrigger`.

## Monitoramento

O Pipeboard oferece um sistema de monitoramento robusto utilizando Prometheus e Grafana:

  * **Prometheus:**
      * Coleta m√©tricas expostas pelos servi√ßos `orion` (Prefect Server) e `worker` (que inclui m√©tricas da aplica√ß√£o ETL).
      * Utiliza o `Pushgateway` para permitir que os fluxos (que s√£o processos de curta dura√ß√£o) enviem suas m√©tricas.
  * **Grafana:**
      * Um dashboard pr√©-configurado (`docs/grafana/grafana_dashboard.json`) est√° dispon√≠vel para visualiza√ß√£o das m√©tricas.
      * **M√©tricas Chave Monitoradas:**
          * **Performance da API Pipedrive:** Tokens consumidos/restantes, lat√™ncia das requisi√ß√µes, total de chamadas por endpoint, status do rate limit, aberturas do circuit breaker.
          * **Sa√∫de dos Fluxos ETL:** Total de execu√ß√µes, falhas, registros processados, tempo desde a √∫ltima execu√ß√£o bem-sucedida/heartbeat, dura√ß√£o m√©dia das execu√ß√µes.
          * **Performance Detalhada do ETL:** Throughput (linhas/segundo), dura√ß√£o de processamento de batches, tamanho dos batches.
          * **Uso de Recursos:** Consumo de mem√≥ria e CPU pelos processos ETL, contagem de threads.
          * **Cache da API:** Taxa de acertos (hits) vs. falhas (misses) do cache Redis.
          * **Sa√∫de do Banco de Dados:** N√∫mero de conex√µes ativas/ociosas no pool.
          * **Status da Aplica√ß√£o:** Uptime dos processos.

## Estrutura de Diret√≥rios

```
pipeboard/
‚îú‚îÄ‚îÄ .github/workflows/        # CI/CD com GitHub Actions
‚îÇ   ‚îî‚îÄ‚îÄ docker-ci.yml
‚îú‚îÄ‚îÄ core/                     # L√≥gica de neg√≥cio principal e schemas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ schemas/              # Modelos de dados Pydantic para entidades Pipedrive
‚îÇ   ‚îî‚îÄ‚îÄ utils/                # Utilit√°rios de schema
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îÇ       ‚îî‚îÄ‚îÄ grafana_dashboard.json # Dashboard Grafana pr√©-configurado
‚îú‚îÄ‚îÄ docker/                   # Configura√ß√µes Docker, Dockerfiles e scripts de entrypoint
‚îÇ   ‚îú‚îÄ‚îÄ scripts/              # Scripts de inicializa√ß√£o para containers
‚îÇ   ‚îú‚îÄ‚îÄ utils/                # Scripts Python para setup de blocos/deployments Prefect
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.orion      # Dockerfile para o servidor Prefect (Orion)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.setup      # Dockerfile para o container de setup do Prefect
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml    # Orquestra√ß√£o dos containers
‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml        # Configura√ß√£o do Prometheus
‚îú‚îÄ‚îÄ infrastructure/           # Adaptadores para tecnologias externas
‚îÇ   ‚îú‚îÄ‚îÄ clients/              # Cliente HTTP para a API Pipedrive
‚îÇ   ‚îú‚îÄ‚îÄ config/               # Configura√ß√µes da aplica√ß√£o (vari√°veis de ambiente)
‚îÇ   ‚îú‚îÄ‚îÄ db/                   # Adaptador para o pool de conex√µes PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ logging.py            # Configura√ß√£o do logging estruturado (structlog)
‚îÇ   ‚îú‚îÄ‚îÄ observability/        # Defini√ß√£o de m√©tricas Prometheus e servidor de m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ prefect/              # Configura√ß√µes espec√≠ficas do Prefect (worker, flow Dockerfile)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ flow/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile.flow # Dockerfile base para os fluxos Prefect
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worker/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Dockerfile.worker
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ run_worker_with_metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ redis/                # Cliente para cache Redis
‚îÇ   ‚îî‚îÄ‚îÄ repositories/         # Reposit√≥rios para persist√™ncia de dados no PostgreSQL
‚îú‚îÄ‚îÄ orchestration/            # Fluxos de ETL e l√≥gica de orquestra√ß√£o com Prefect
‚îÇ   ‚îú‚îÄ‚îÄ common/               # Utilit√°rios e l√≥gica compartilhada pelos fluxos
‚îÇ   ‚îú‚îÄ‚îÄ flows/                # Defini√ß√£o dos fluxos Prefect para cada entidade
‚îÇ   ‚îî‚îÄ‚îÄ plugins/              # Scripts para registrar os deployments dos fluxos no Prefect
‚îú‚îÄ‚îÄ .env.example              # Arquivo de exemplo para vari√°veis de ambiente
‚îú‚îÄ‚îÄ README.md                 # Este arquivo
‚îú‚îÄ‚îÄ requirements.txt          # Depend√™ncias Python (a serem geradas/atualizadas)
‚îî‚îÄ‚îÄ run_project.sh            # Script principal para construir e iniciar o ambiente Docker
```

## Vari√°veis de Ambiente Essenciais

Estas vari√°veis devem ser definidas no seu arquivo `.env` na raiz do projeto:

  * `PIPEDRIVE_API_KEY`: Sua chave de API do Pipedrive.
  * `POSTGRES_DB`: Nome do banco de dados PostgreSQL.
  * `POSTGRES_USER`: Usu√°rio do PostgreSQL.
  * `POSTGRES_PASSWORD`: Senha do usu√°rio do PostgreSQL.
  * `POSTGRES_HOST`: Host do PostgreSQL (geralmente o nome do servi√ßo Docker, ex: `db`).
  * `POSTGRES_PORT`: Porta do PostgreSQL.
  * `DATABASE_URL`: URL de conex√£o completa para o PostgreSQL (ex: `postgresql://user:pass@host:port/db`).
  * `REDIS_URL`: URL de conex√£o para o Redis (ex: `redis://redis:6379/0`).
  * `PREFECT_API_URL`: URL da API do servidor Prefect (Orion) (ex: `http://orion:4200/api`).
  * `PREFECT_WORK_POOL_NAME`: Nome do work pool do Prefect que o worker escutar√° (ex: `pipeboard-docker-pool`).
  * `IMAGE_NAME`: Nome da imagem Docker base a ser usada para os jobs dos fluxos Prefect (ex: `user/pipeboard-flow`).
  * `DEFAULT_DOCKER_NETWORK_NAME`: Nome da rede Docker interna usada pelo Docker Compose (ex: `prefect_internal_network`).
  * `HOST_PREFECT_PORT`: Porta no seu host para acessar a UI do Prefect (ex: `4200`).
  * `HOST_GRAFANA_PORT`: Porta no seu host para acessar o Grafana (ex: `3000`).
  * `PUSHGATEWAY_ADDRESS`: Endere√ßo do Prometheus Pushgateway (ex: `pushgateway:9091`).

## Desenvolvimento e Contribui√ß√£o

1.  **Fork o Reposit√≥rio** no GitHub.
2.  **Crie uma Branch para sua Feature:**
    ```bash
    git checkout -b feature/sua-feature-incrivel
    ```
3.  **Desenvolva e Fa√ßa Commits:** Siga o padr√£o de [Conventional Commits](https://www.conventionalcommits.org/) para mensagens de commit.
4.  **Abra um Pull Request:** Detalhe as mudan√ßas realizadas e o motivo.

Para o ambiente de desenvolvimento local, ap√≥s clonar o reposit√≥rio e configurar o `.env`, voc√™ pode usar o `run_project.sh` ou `docker compose up -d` para iniciar todos os servi√ßos. As altera√ß√µes no c√≥digo Python dentro dos volumes montados (se configurado no `docker-compose.yml` para desenvolvimento) podem ser refletidas nos containers (especialmente para scripts, ou se o servidor Prefect/worker for reiniciado ou usar um modo de desenvolvimento que recarregue o c√≥digo).

## Solu√ß√£o de Problemas (FAQ)

  * **Problema: Erros de conex√£o com o banco de dados ou Redis ao iniciar.**
      * **Solu√ß√£o:** Verifique se os servi√ßos `db` e `redis` est√£o saud√°veis no `docker compose ps`. Confira as vari√°veis `DATABASE_URL` e `REDIS_URL` no seu arquivo `.env` e se os nomes dos hosts correspondem aos nomes dos servi√ßos no `docker-compose.yml`. Garanta que as credenciais do PostgreSQL est√£o corretas.
  * **Problema: Fluxos Prefect n√£o s√£o executados ou ficam presos no estado "Pending".**
      * **Solu√ß√£o:**
          * Verifique se o servi√ßo `worker` est√° rodando e conectado ao `PREFECT_API_URL` correto.
          * Confira os logs do `worker` (`docker compose logs -f worker`).
          * Certifique-se de que o `PREFECT_WORK_POOL_NAME` configurado nos deployments dos fluxos (em `orchestration/plugins/`) corresponde ao nome do work pool que o worker est√° escutando.
          * Verifique se a imagem Docker especificada nos deployments (`IMAGE_NAME`) est√° acess√≠vel (puxada localmente ou em um registry).
  * **Problema: API do Pipedrive retorna erros 401 (Unauthorized).**
      * **Solu√ß√£o:** Confirme se a `PIPEDRIVE_API_KEY` no seu arquivo `.env` √© v√°lida e possui as permiss√µes necess√°rias.
  * **Problema: API do Pipedrive retorna erros 403 (Forbidden) ou 429 (Rate Limit).**
      * **Solu√ß√£o:** O Pipeboard possui retries e circuit breaker. Se os erros 429 persistirem, voc√™ pode estar excedendo os limites da API do Pipedrive. Verifique o dashboard do Grafana para o consumo de tokens. O erro 403 pode indicar falta de permiss√£o para acessar um endpoint espec√≠fico.
  * **Problema: O dashboard do Grafana n√£o mostra dados.**
      * **Solu√ß√£o:**
          * Verifique se o Prometheus est√° coletando m√©tricas dos targets (`orion`, `worker`, `pushgateway`). Acesse a UI do Prometheus (`http://localhost:9090`).
          * Confirme se a fonte de dados (datasource) Prometheus est√° configurada corretamente no Grafana.
          * Garanta que os fluxos ETL est√£o rodando e enviando m√©tricas para o Pushgateway.

## Licen√ßa

Este projeto est√° licenciado sob a [Licen√ßa GNU](https://www.gnu.org/licenses/gpl-3.0.html).
